{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b17b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import json\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "mpl.style.use('seaborn-colorblind')\n",
    "mpl.rc('font', size=15)\n",
    "mpl.rc('figure', figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b0a49b",
   "metadata": {},
   "source": [
    "## Split the dataset randomly by stars\n",
    "\n",
    "In this section, we split the dataset into a train, validation, and test set randomly based on a given proportion. Because the dataset is split randomly, stars that belong to the same stream/cluster (same `parentid`) can belong to different dataset. This can potentially overfit, because the network can simple remember the properties of each stream. In the section below, we will split the dataset by stream, such that no stream in the training dataset would appear in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54707d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/scratch/08317/tg876168/ananke_subsamples/m12i/lsr-0/accreted_stellar_mass_all/lsr-0-rslice-0.m12i-res7100-subsamples.hdf5',\n",
       " '/scratch/08317/tg876168/ananke_subsamples/m12i/lsr-0/accreted_stellar_mass_all/lsr-0-rslice-1.m12i-res7100-subsamples.hdf5']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sim_dir = '/scratch/08317/tg876168/ananke_subsamples/m12i/lsr-0/'\n",
    "sim_dir = '/scratch/08317/tg876168/ananke_subsamples/m12i/lsr-0/accreted_stellar_mass_all/'\n",
    "sim_files = sorted(glob.glob(os.path.join(sim_dir, '*.hdf5')))\n",
    "sim_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7db49fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'dec', 'feh', 'l', 'labels', 'parallax', 'parallax_over_error', 'parentid', 'pmdec', 'pmra', 'px_true', 'py_true', 'pz_true', 'ra', 'radial_velocity', 'source_id', 'vx_true', 'vy_true', 'vz_true']\n",
      "411177\n",
      "['b', 'dec', 'feh', 'l', 'labels', 'parallax', 'parallax_over_error', 'parentid', 'pmdec', 'pmra', 'px_true', 'py_true', 'pz_true', 'ra', 'radial_velocity', 'source_id', 'vx_true', 'vy_true', 'vz_true']\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "for i_file in range(len(sim_files)):\n",
    "    with h5py.File(sim_files[i_file], 'r') as f:\n",
    "        print(list(f.keys()))\n",
    "        print(f['ra'].len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15c5591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ('l', 'b', 'parallax', 'pmra', 'pmdec', 'radial_velocity', 'feh', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c2081d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = []\n",
    "for sim_file in sim_files:\n",
    "    with h5py.File(sim_file, 'r') as input_f:\n",
    "        full_data.append(input_f['labels'][:])\n",
    "full_data = np.concatenate(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "230223fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 6.20264064e+08],\n",
       "       [1.00000000e+00, 6.20264064e+08],\n",
       "       [1.00000000e+00, 6.20264064e+08],\n",
       "       ...,\n",
       "       [1.00000000e+00, 2.76076256e+08],\n",
       "       [1.00000000e+00, 1.98836448e+08],\n",
       "       [0.00000000e+00, 8.07089950e+06]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c47b03",
   "metadata": {},
   "source": [
    "### Split data into train, validation, and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0728e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed1 = 5642556\n",
    "seed2 = 7196865\n",
    "\n",
    "# n_max_file = 10000    # 1M samples per file\n",
    "n_max_file = 10000000    # 10M samples per file\n",
    "\n",
    "out_dir_base = '/scratch/08317/tg876168/dataset/m12i-lsr-0-stellar-mass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1acb1fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in keys:\n",
    "    full_data = []\n",
    "    for sim_file in sim_files:\n",
    "        with h5py.File(sim_file, 'r') as input_f:\n",
    "            full_data.append(input_f[p][:])\n",
    "    full_data = np.concatenate(full_data)\n",
    "    \n",
    "    # split dataset into training and validation\n",
    "    train_data, val_data = train_test_split(\n",
    "        full_data, test_size=0.2, random_state=seed1, shuffle=True)\n",
    "    val_data, test_data = train_test_split(\n",
    "        val_data, test_size=0.5, random_state=seed2, shuffle=True)\n",
    "    \n",
    "    # write each dataset\n",
    "    for data, flag in zip(\n",
    "        (train_data, val_data, test_data), ('train', 'val', 'test')):\n",
    "        n_file = data.shape[0] // n_max_file + 1\n",
    "        \n",
    "        out_dir = os.path.join(out_dir_base, flag)     \n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        \n",
    "        for i in range(n_file):\n",
    "            file = os.path.join(out_dir, 'n{:02d}.hdf5'.format(i))\n",
    "            with h5py.File(file, 'a') as output_f:\n",
    "                # write sliced dataset to file\n",
    "                start = i * n_max_file\n",
    "                end = (i + 1) * n_max_file\n",
    "                output_f.create_dataset(p, data=data[start: end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "431e622a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Number of class 0 samples: 6828\n",
      "Fraction of class 0 samples: 0.0279\n",
      "Number of class 1 samples: 238264\n",
      "Fraction of class 1 samples: 0.9721\n",
      "---------------\n",
      "val\n",
      "Number of class 0 samples: 829\n",
      "Fraction of class 0 samples: 0.0271\n",
      "Number of class 1 samples: 29808\n",
      "Fraction of class 1 samples: 0.9729\n",
      "---------------\n",
      "test\n",
      "Number of class 0 samples: 852\n",
      "Fraction of class 0 samples: 0.0278\n",
      "Number of class 1 samples: 29785\n",
      "Fraction of class 1 samples: 0.9722\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# print out the counts and fraction of in situ and accreted stars for each flag\n",
    "# we want to make sure each flag is drawn from the same distribution\n",
    "properties = {}\n",
    "\n",
    "for flag in ('train', 'val', 'test'):\n",
    "    files = sorted(glob.glob(os.path.join(out_dir_base, f'{flag}/*')))\n",
    "\n",
    "    labels = []\n",
    "    for file in files:\n",
    "        with h5py.File(file, 'r') as f:\n",
    "            labels.append(f['labels'][:])\n",
    "    labels = np.concatenate(labels)\n",
    "    n_total = len(labels)\n",
    "\n",
    "    print(flag)\n",
    "    temp = {}\n",
    "    for l in np.unique(labels):\n",
    "        n = int(np.sum(labels==l))\n",
    "        temp['n_{}'.format(l)] = n\n",
    "        temp['f_{}'.format(l)] = n / n_total\n",
    "        \n",
    "        print('Number of class {:d} samples: {:d}'.format(l, n))\n",
    "        print('Fraction of class {:d} samples: {:.4f}'.format(l, n / n_total))\n",
    "    \n",
    "    properties[flag] = temp\n",
    "                \n",
    "    print('---------------')\n",
    "\n",
    "\n",
    "with open(os.path.join(out_dir_base, 'properties.json'), 'w') as f:\n",
    "    json.dump(properties, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9af1cc7",
   "metadata": {},
   "source": [
    "### Preprocessing dict\n",
    "During training, we will scale the training data such that for each feature, the mean and standard deviation is 0 and 1, respectively. We want to compute these values prior to training and store it somewhere such that it can be read easily (and quickly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6745e71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: l\n",
      "Mean: -1.5467e+00\n",
      "stdv: 9.8288e+01\n",
      "----------------\n",
      "Keys: b\n",
      "Mean: 3.0008e+00\n",
      "stdv: 3.7832e+01\n",
      "----------------\n",
      "Keys: parallax\n",
      "Mean: 1.2507e+00\n",
      "stdv: 1.0972e+00\n",
      "----------------\n",
      "Keys: pmra\n",
      "Mean: -6.7181e+00\n",
      "stdv: 7.2136e+01\n",
      "----------------\n",
      "Keys: pmdec\n",
      "Mean: -3.5606e+01\n",
      "stdv: 8.2909e+01\n",
      "----------------\n",
      "Keys: radial_velocity\n",
      "Mean: -9.9484e+00\n",
      "stdv: 2.3880e+02\n",
      "----------------\n",
      "Keys: feh\n",
      "Mean: -1.5453e+00\n",
      "stdv: 5.0982e-01\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "train_files = sorted(glob.glob(os.path.join(out_dir_base, 'train/*')))\n",
    "\n",
    "preprocess_dict = {}\n",
    "\n",
    "# loop over all keys and compute mean and stdv\n",
    "for p in keys:\n",
    "    if p == 'labels':\n",
    "        continue\n",
    "    data = []\n",
    "    for file in train_files:\n",
    "        with h5py.File(file, 'r') as f:\n",
    "            data.append(f[p][:])\n",
    "    data = np.concatenate(data)\n",
    "    \n",
    "    mean = np.nanmean(data)\n",
    "    stdv = np.nanstd(data)\n",
    "    \n",
    "    print(f'Keys: {p}')\n",
    "    print('Mean: {:.4e}'.format(mean))\n",
    "    print('stdv: {:.4e}'.format(stdv))\n",
    "    print('----------------')\n",
    "    \n",
    "    preprocess_dict[p] = {\n",
    "        'mean': float(mean), \n",
    "        'stdv': float(stdv),\n",
    "    }\n",
    "    \n",
    "with open(os.path.join(out_dir_base, 'preprocess.json'), 'w') as f:\n",
    "    json.dump(preprocess_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac18a7c",
   "metadata": {},
   "source": [
    "### Radial velocity dataset\n",
    "For many stars, we do not have access to radial velocity information. We can apply a non-NaN cut on the radial velocity of our original dataset, but it is faster to create a second dataset with only stars that have radial velocity information (though it would take more disk space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7894144a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/08317/tg876168/dataset/m12i-lsr-0-stellar-mass-rv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir_base_rv = out_dir_base + '-rv'\n",
    "out_dir_base_rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2232dca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Number of class 0 samples: 804\n",
      "Fraction of class 0 samples: 0.0238\n",
      "Number of class 1 samples: 32949\n",
      "Fraction of class 1 samples: 0.9762\n",
      "---------------\n",
      "Keys: l\n",
      "Mean: -1.8911e+00\n",
      "stdv: 9.8613e+01\n",
      "----------------\n",
      "Keys: b\n",
      "Mean: 3.1147e+00\n",
      "stdv: 3.7433e+01\n",
      "----------------\n",
      "Keys: parallax\n",
      "Mean: 1.4671e+00\n",
      "stdv: 1.8777e+00\n",
      "----------------\n",
      "Keys: pmra\n",
      "Mean: -7.2363e+00\n",
      "stdv: 1.0059e+02\n",
      "----------------\n",
      "Keys: pmdec\n",
      "Mean: -4.0649e+01\n",
      "stdv: 1.2383e+02\n",
      "----------------\n",
      "Keys: radial_velocity\n",
      "Mean: -9.9484e+00\n",
      "stdv: 2.3880e+02\n",
      "----------------\n",
      "Keys: feh\n",
      "Mean: -1.4937e+00\n",
      "stdv: 4.9026e-01\n",
      "----------------\n",
      "val\n",
      "Number of class 0 samples: 107\n",
      "Fraction of class 0 samples: 0.0249\n",
      "Number of class 1 samples: 4195\n",
      "Fraction of class 1 samples: 0.9751\n",
      "---------------\n",
      "test\n",
      "Number of class 0 samples: 102\n",
      "Fraction of class 0 samples: 0.0243\n",
      "Number of class 1 samples: 4092\n",
      "Fraction of class 1 samples: 0.9757\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# read in input files from the original dataset and copy them selectively\n",
    "# print out the counts and fraction of in situ and accreted stars for each flag\n",
    "# we want to make sure each flag is drawn from the same distribution\n",
    "properties = {}\n",
    "preprocess_dict = {}\n",
    "\n",
    "for flag in ('train', 'val', 'test'):\n",
    "    \n",
    "    # create a new dataset directory\n",
    "    out_dir = os.path.join(out_dir_base_rv, flag)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    # iterate over all dataset files\n",
    "    in_files = sorted(glob.glob(os.path.join(out_dir_base, f'{flag}/*')))\n",
    "    for i, in_file in enumerate(in_files):\n",
    "        \n",
    "        out_file = os.path.join(out_dir, 'n{:02d}.hdf5'.format(i))\n",
    "        \n",
    "        with h5py.File(in_file, 'r') as input_f:\n",
    "            with h5py.File(out_file, 'w') as output_f:\n",
    "\n",
    "                # only consider stars with radial velocity information\n",
    "                rv = input_f['radial_velocity'][:]\n",
    "                rv_isnotnan = ~np.isnan(rv)\n",
    "            \n",
    "                for p in input_f.keys():\n",
    "                    output_f.create_dataset(p, data=input_f[p][rv_isnotnan])\n",
    "    \n",
    "    # recompute the number of in situ and accreted samples in the new dataset\n",
    "    labels = []\n",
    "    out_files = sorted(glob.glob(os.path.join(out_dir_base_rv, f'{flag}/*')))    \n",
    "    for file in out_files:\n",
    "        with h5py.File(file, 'r') as f:\n",
    "            labels.append(f['labels'][:])\n",
    "    labels = np.concatenate(labels)\n",
    "    n_total = len(labels)\n",
    "\n",
    "    print(flag)\n",
    "    temp = {}\n",
    "    for l in np.unique(labels):\n",
    "        n = int(np.sum(labels==l))\n",
    "        temp['n_{}'.format(l)] = n\n",
    "        temp['f_{}'.format(l)] = n / n_total\n",
    "        \n",
    "        print('Number of class {:d} samples: {:d}'.format(l, n))\n",
    "        print('Fraction of class {:d} samples: {:.4f}'.format(l, n / n_total))\n",
    "    \n",
    "    properties[flag] = temp\n",
    "                \n",
    "    print('---------------')\n",
    "\n",
    "    # if training data, we will also recompute the mean\n",
    "    # and standard deviation after the radial-velocity cut\n",
    "    if flag == 'train':\n",
    "        for p in keys:\n",
    "            if p == 'labels':\n",
    "                continue\n",
    "            data = []\n",
    "            for file in out_files:\n",
    "                with h5py.File(file, 'r') as f:\n",
    "                    data.append(f[p][:])\n",
    "            data = np.concatenate(data)\n",
    "            mean = np.nanmean(data)\n",
    "            stdv = np.nanstd(data)\n",
    "\n",
    "            print(f'Keys: {p}')\n",
    "            print('Mean: {:.4e}'.format(mean))\n",
    "            print('stdv: {:.4e}'.format(stdv))\n",
    "            print('----------------')\n",
    "\n",
    "            preprocess_dict[p] = {\n",
    "                'mean': float(mean), \n",
    "                'stdv': float(stdv),\n",
    "            }\n",
    "\n",
    "            \n",
    "# write dataset properties and preprocessing dict to JSON files in new directory\n",
    "with open(os.path.join(out_dir_base_rv, 'properties.json'), 'w') as f:\n",
    "    json.dump(properties, f, indent=4)\n",
    "with open(os.path.join(out_dir_base_rv, 'preprocess.json'), 'w') as f:\n",
    "    json.dump(preprocess_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fd3917",
   "metadata": {},
   "source": [
    "## Split the dataset randomly by particles\n",
    "\n",
    "In this section, instead of splitting the dataset randomly by stars, we split it by particles. This helps prevent the network from simply remembering the properties of each merger. It's worth noting that one merger can contain multiple particles, so this method is not completely fool-proof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce565845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/scratch/08317/tg876168/ananke_subsamples/m12i/lsr-0/accreted_stellar_mass_all/lsr-0-rslice-0.m12i-res7100-subsamples.hdf5',\n",
       " '/scratch/08317/tg876168/ananke_subsamples/m12i/lsr-0/accreted_stellar_mass_all/lsr-0-rslice-1.m12i-res7100-subsamples.hdf5']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sim_dir = '/scratch/08317/tg876168/ananke_subsamples/m12i/lsr-0/'\n",
    "sim_dir = '/scratch/08317/tg876168/ananke_subsamples/m12i/lsr-0/accreted_stellar_mass_all/'\n",
    "sim_files = sorted(glob.glob(os.path.join(sim_dir, '*.hdf5')))\n",
    "sim_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb8cc32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'dec', 'feh', 'l', 'labels', 'parallax', 'parallax_over_error', 'parentid', 'pmdec', 'pmra', 'px_true', 'py_true', 'pz_true', 'ra', 'radial_velocity', 'source_id', 'vx_true', 'vy_true', 'vz_true']\n",
      "411177\n",
      "['b', 'dec', 'feh', 'l', 'labels', 'parallax', 'parallax_over_error', 'parentid', 'pmdec', 'pmra', 'px_true', 'py_true', 'pz_true', 'ra', 'radial_velocity', 'source_id', 'vx_true', 'vy_true', 'vz_true']\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "for i_file in range(len(sim_files)):\n",
    "    with h5py.File(sim_files[i_file], 'r') as f:\n",
    "        print(list(f.keys()))\n",
    "        print(f['ra'].len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d1889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ('l', 'b', 'parallax', 'pmra', 'pmdec', 'radial_velocity', 'feh', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df1ae9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed1 = 5642556\n",
    "seed2 = 7196865\n",
    "\n",
    "# n_max_file = 10000    # 1M samples per file\n",
    "n_max_file = 10000000    # 10M samples per file\n",
    "\n",
    "out_dir_base = '/scratch/08317/tg876168/dataset/accreted_stellar_mass_all/dset-particles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c521d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the simulation files, read in the parentid of each star\n",
    "# the parentid determines the stream/cluster the star originally belong too in FIRE\n",
    "parentid = []\n",
    "labels = []\n",
    "for sim_file in sim_files:\n",
    "    with h5py.File(sim_file, 'r') as input_f:\n",
    "        parentid.append(input_f['parentid'][:])\n",
    "        labels.append(input_f['labels'][:])\n",
    "parentid = np.concatenate(parentid)\n",
    "labels = np.concatenate(labels)\n",
    "\n",
    "# also read in the mass of each parentid\n",
    "with h5py.File('/scratch/08317/tg876168/labels_mapping/accreted_stellar_mass_all.hdf5', 'r') as f:\n",
    "    mass = 10**f['log10_halo_stellar_mass'][:]\n",
    "    particle_id = f['id_stars'][:]\n",
    "    merger_count = f['merger_count'][:]\n",
    "    \n",
    "    sort = np.argsort(particle_id)\n",
    "    particle_id = particle_id[sort]\n",
    "    mass = mass[sort]\n",
    "    \n",
    "    thres = f.attrs['threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "469f3f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique parent id\n",
    "unique, counts = np.unique(parentid, return_counts=True)\n",
    "\n",
    "# shuffle \n",
    "shuffle = np.random.permutation(len(unique))\n",
    "unique = unique[shuffle]\n",
    "counts = counts[shuffle]\n",
    "cum_counts = np.cumsum(counts)\n",
    "\n",
    "# calculate the number of stars in each dataset and split\n",
    "N_total = len(labels)\n",
    "N_val = int(N_total * 0.1)\n",
    "N_test = int(N_total * 0.1)\n",
    "N_train = N_total - N_val - N_test\n",
    "\n",
    "# partition parentid into train, val, test dataset \n",
    "part = []\n",
    "part.append(np.where(cum_counts > N_train)[0][0])\n",
    "part.append(np.where(cum_counts > N_train + N_val)[0][0])\n",
    "part_parentid = {\n",
    "    'train': unique[: part[0]],\n",
    "    'val': unique[part[0]: part[1]],\n",
    "    'test': unique[part[1]:]\n",
    "}\n",
    "\n",
    "# get the index of each star in each dataset\n",
    "train_idx = np.array([i for i in range(len(parentid)) \n",
    "                      if parentid[i] in part_parentid['train']])\n",
    "val_idx = np.array([i for i in range(len(parentid)) \n",
    "                    if parentid[i] in part_parentid['val']])\n",
    "test_idx = np.array([i for i in range(len(parentid)) \n",
    "                     if parentid[i] in part_parentid['test']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d3b644",
   "metadata": {},
   "source": [
    "First, we want to check the mass distribution of the particles for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bf3f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to check the mass distribution of the particle for each set\n",
    "train_mass = np.array([mass[i] for i in range(len(particle_id)) \n",
    "                       if particle_id[i] in part_parentid['train']])\n",
    "val_mass = np.array([mass[i] for i in range(len(particle_id)) \n",
    "                       if particle_id[i] in part_parentid['val']])\n",
    "test_mass = np.array([mass[i] for i in range(len(particle_id)) \n",
    "                       if particle_id[i] in part_parentid['test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1184790c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "bins = 10**np.linspace(4, 9, 30)\n",
    "\n",
    "# train\n",
    "counts, bins = np.histogram(train_mass, bins)\n",
    "counts = counts / np.sum(counts)  # normalize by the total number (not the area)\n",
    "ax.hist(bins[:-1], bins, weights=counts, histtype='step', \n",
    "        lw=2, zorder=10, color='k', alpha=0.9, ls='--', label='train')\n",
    "\n",
    "# val\n",
    "counts, bins = np.histogram(val_mass, bins)\n",
    "counts = counts / np.sum(counts)  # normalize by the total number (not the area)\n",
    "ax.hist(bins[:-1], bins, weights=counts,\n",
    "        lw=2, zorder=8, alpha=0.7, ls='--', label='val')\n",
    "\n",
    "# # test\n",
    "# counts, bins = np.histogram(test_mass, bins)\n",
    "# counts = counts / np.sum(counts)  # normalize by the total number (not the area)\n",
    "# ax.hist(bins[:-1], bins, weights=counts, histtype='step', \n",
    "#         lw=2, zorder=9, color='r', label='test')\n",
    "\n",
    "# format axis and figure\n",
    "ax.axvline(thres, color='k', ls='--')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(r'Subhalo Mass [$M_\\odot$]')\n",
    "ax.set_ylabel('Counts')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d107ac",
   "metadata": {},
   "source": [
    "Because everything seems right, we begin split the dataset using the split above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25b304f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in keys:\n",
    "    full_data = []\n",
    "    for sim_file in sim_files:\n",
    "        with h5py.File(sim_file, 'r') as input_f:\n",
    "            full_data.append(input_f[p][:])\n",
    "    full_data = np.concatenate(full_data)\n",
    "    \n",
    "    # quick fix for label\n",
    "    # TODO: find a perma fix\n",
    "    if p == 'labels':\n",
    "        full_data = full_data[:, 0]\n",
    "\n",
    "    \n",
    "    # split the dataset into training, validation, and test set    \n",
    "    train_data = full_data[train_idx]\n",
    "    val_data = full_data[val_idx]\n",
    "    test_data = full_data[test_idx]\n",
    "    \n",
    "    # write each dataset\n",
    "    for data, flag in zip(\n",
    "        (train_data, val_data, test_data), ('train', 'val', 'test')):\n",
    "        n_file = data.shape[0] // n_max_file + 1\n",
    "        \n",
    "        out_dir = os.path.join(out_dir_base, flag)     \n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        \n",
    "        for i in range(n_file):\n",
    "            file = os.path.join(out_dir, 'n{:02d}.hdf5'.format(i))\n",
    "            with h5py.File(file, 'a') as output_f:\n",
    "                # write sliced dataset to file\n",
    "                start = i * n_max_file\n",
    "                end = (i + 1) * n_max_file\n",
    "                output_f.create_dataset(p, data=data[start: end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d822f00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Number of class 0 samples: 15855\n",
      "Fraction of class 0 samples: 0.0482\n",
      "Number of class 1 samples: 313059\n",
      "Fraction of class 1 samples: 0.9518\n",
      "---------------\n",
      "val\n",
      "Number of class 0 samples: 1485\n",
      "Fraction of class 0 samples: 0.0361\n",
      "Number of class 1 samples: 39602\n",
      "Fraction of class 1 samples: 0.9639\n",
      "---------------\n",
      "test\n",
      "Number of class 0 samples: 2633\n",
      "Fraction of class 0 samples: 0.0639\n",
      "Number of class 1 samples: 38596\n",
      "Fraction of class 1 samples: 0.9361\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# print out the counts and fraction of in situ and accreted stars for each flag\n",
    "# we want to make sure each flag is drawn from the same distribution\n",
    "properties = {}\n",
    "\n",
    "for flag in ('train', 'val', 'test'):\n",
    "    files = sorted(glob.glob(os.path.join(out_dir_base, f'{flag}/*')))\n",
    "\n",
    "    labels = []\n",
    "    for file in files:\n",
    "        with h5py.File(file, 'r') as f:\n",
    "            labels.append(f['labels'][:])\n",
    "    labels = np.concatenate(labels)\n",
    "    n_total = len(labels)\n",
    "\n",
    "    print(flag)\n",
    "    temp = {}\n",
    "    for l in np.unique(labels):\n",
    "        l = int(l)\n",
    "        n = int(np.sum(labels==l))\n",
    "        temp['n_{}'.format(l)] = n\n",
    "        temp['f_{}'.format(l)] = n / n_total\n",
    "        \n",
    "        print('Number of class {:d} samples: {:d}'.format(l, n))\n",
    "        print('Fraction of class {:d} samples: {:.4f}'.format(l, n / n_total))\n",
    "    \n",
    "    properties[flag] = temp\n",
    "                \n",
    "    print('---------------')\n",
    "\n",
    "\n",
    "with open(os.path.join(out_dir_base, 'properties.json'), 'w') as f:\n",
    "    json.dump(properties, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23a0598e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: l\n",
      "Mean: -2.0830e+00\n",
      "stdv: 9.9275e+01\n",
      "----------------\n",
      "Keys: b\n",
      "Mean: 2.1444e+00\n",
      "stdv: 3.8874e+01\n",
      "----------------\n",
      "Keys: parallax\n",
      "Mean: 1.1575e+00\n",
      "stdv: 9.7349e-01\n",
      "----------------\n",
      "Keys: pmra\n",
      "Mean: -4.1569e+00\n",
      "stdv: 6.3547e+01\n",
      "----------------\n",
      "Keys: pmdec\n",
      "Mean: -3.4238e+01\n",
      "stdv: 7.0146e+01\n",
      "----------------\n",
      "Keys: radial_velocity\n",
      "Mean: -1.8132e+00\n",
      "stdv: 2.2436e+02\n",
      "----------------\n",
      "Keys: feh\n",
      "Mean: -1.6138e+00\n",
      "stdv: 5.2611e-01\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "train_files = sorted(glob.glob(os.path.join(out_dir_base, 'train/*')))\n",
    "\n",
    "preprocess_dict = {}\n",
    "\n",
    "# loop over all keys and compute mean and stdv\n",
    "for p in keys:\n",
    "    if p == 'labels':\n",
    "        continue\n",
    "    data = []\n",
    "    for file in train_files:\n",
    "        with h5py.File(file, 'r') as f:\n",
    "            data.append(f[p][:])\n",
    "    data = np.concatenate(data)\n",
    "    \n",
    "    mean = np.nanmean(data)\n",
    "    stdv = np.nanstd(data)\n",
    "    \n",
    "    print(f'Keys: {p}')\n",
    "    print('Mean: {:.4e}'.format(mean))\n",
    "    print('stdv: {:.4e}'.format(stdv))\n",
    "    print('----------------')\n",
    "    \n",
    "    preprocess_dict[p] = {\n",
    "        'mean': float(mean), \n",
    "        'stdv': float(stdv),\n",
    "    }\n",
    "    \n",
    "with open(os.path.join(out_dir_base, 'preprocess.json'), 'w') as f:\n",
    "    json.dump(preprocess_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc8174",
   "metadata": {},
   "source": [
    "### Radial velocity dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f1a13e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/08317/tg876168/dataset/accreted_stellar_mass_all/dset-particles-rv'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir_base_rv = out_dir_base + '-rv'\n",
    "out_dir_base_rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98c88944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Number of class 0 samples: 1970\n",
      "Fraction of class 0 samples: 0.0435\n",
      "Number of class 1 samples: 43325\n",
      "Fraction of class 1 samples: 0.9565\n",
      "---------------\n",
      "Keys: l\n",
      "Mean: -2.1842e+00\n",
      "stdv: 9.9242e+01\n",
      "----------------\n",
      "Keys: b\n",
      "Mean: 2.2438e+00\n",
      "stdv: 3.8612e+01\n",
      "----------------\n",
      "Keys: parallax\n",
      "Mean: 1.2926e+00\n",
      "stdv: 1.5820e+00\n",
      "----------------\n",
      "Keys: pmra\n",
      "Mean: -4.0748e+00\n",
      "stdv: 8.6690e+01\n",
      "----------------\n",
      "Keys: pmdec\n",
      "Mean: -3.8248e+01\n",
      "stdv: 9.6884e+01\n",
      "----------------\n",
      "Keys: radial_velocity\n",
      "Mean: -1.8132e+00\n",
      "stdv: 2.2436e+02\n",
      "----------------\n",
      "Keys: feh\n",
      "Mean: -1.5666e+00\n",
      "stdv: 5.1834e-01\n",
      "----------------\n",
      "val\n",
      "Number of class 0 samples: 176\n",
      "Fraction of class 0 samples: 0.0292\n",
      "Number of class 1 samples: 5848\n",
      "Fraction of class 1 samples: 0.9708\n",
      "---------------\n",
      "test\n",
      "Number of class 0 samples: 325\n",
      "Fraction of class 0 samples: 0.0553\n",
      "Number of class 1 samples: 5555\n",
      "Fraction of class 1 samples: 0.9447\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# read in input files from the original dataset and copy them selectively\n",
    "# print out the counts and fraction of in situ and accreted stars for each flag\n",
    "# we want to make sure each flag is drawn from the same distribution\n",
    "properties = {}\n",
    "preprocess_dict = {}\n",
    "\n",
    "for flag in ('train', 'val', 'test'):\n",
    "    \n",
    "    # create a new dataset directory\n",
    "    out_dir = os.path.join(out_dir_base_rv, flag)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    # iterate over all dataset files\n",
    "    in_files = sorted(glob.glob(os.path.join(out_dir_base, f'{flag}/*')))\n",
    "    for i, in_file in enumerate(in_files):\n",
    "        \n",
    "        out_file = os.path.join(out_dir, 'n{:02d}.hdf5'.format(i))\n",
    "        \n",
    "        with h5py.File(in_file, 'r') as input_f:\n",
    "            with h5py.File(out_file, 'w') as output_f:\n",
    "\n",
    "                # only consider stars with radial velocity information\n",
    "                rv = input_f['radial_velocity'][:]\n",
    "                rv_isnotnan = ~np.isnan(rv)\n",
    "            \n",
    "                for p in input_f.keys():\n",
    "                    output_f.create_dataset(p, data=input_f[p][rv_isnotnan])\n",
    "    \n",
    "    # recompute the number of in situ and accreted samples in the new dataset\n",
    "    labels = []\n",
    "    out_files = sorted(glob.glob(os.path.join(out_dir_base_rv, f'{flag}/*')))    \n",
    "    for file in out_files:\n",
    "        with h5py.File(file, 'r') as f:\n",
    "            labels.append(f['labels'][:])\n",
    "    labels = np.concatenate(labels)\n",
    "    n_total = len(labels)\n",
    "\n",
    "    print(flag)\n",
    "    temp = {}\n",
    "    for l in np.unique(labels):\n",
    "        l = int(l)\n",
    "        n = int(np.sum(labels==l))\n",
    "        temp['n_{}'.format(l)] = n\n",
    "        temp['f_{}'.format(l)] = n / n_total\n",
    "        \n",
    "        print('Number of class {:d} samples: {:d}'.format(l, n))\n",
    "        print('Fraction of class {:d} samples: {:.4f}'.format(l, n / n_total))\n",
    "    \n",
    "    properties[flag] = temp\n",
    "                \n",
    "    print('---------------')\n",
    "\n",
    "    # if training data, we will also recompute the mean\n",
    "    # and standard deviation after the radial-velocity cut\n",
    "    if flag == 'train':\n",
    "        for p in keys:\n",
    "            if p == 'labels':\n",
    "                continue\n",
    "            data = []\n",
    "            for file in out_files:\n",
    "                with h5py.File(file, 'r') as f:\n",
    "                    data.append(f[p][:])\n",
    "            data = np.concatenate(data)\n",
    "            mean = np.nanmean(data)\n",
    "            stdv = np.nanstd(data)\n",
    "\n",
    "            print(f'Keys: {p}')\n",
    "            print('Mean: {:.4e}'.format(mean))\n",
    "            print('stdv: {:.4e}'.format(stdv))\n",
    "            print('----------------')\n",
    "\n",
    "            preprocess_dict[p] = {\n",
    "                'mean': float(mean), \n",
    "                'stdv': float(stdv),\n",
    "            }\n",
    "\n",
    "            \n",
    "# write dataset properties and preprocessing dict to JSON files in new directory\n",
    "with open(os.path.join(out_dir_base_rv, 'properties.json'), 'w') as f:\n",
    "    json.dump(properties, f, indent=4)\n",
    "with open(os.path.join(out_dir_base_rv, 'preprocess.json'), 'w') as f:\n",
    "    json.dump(preprocess_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c0b01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
